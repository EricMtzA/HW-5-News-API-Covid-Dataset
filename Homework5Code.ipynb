!pip install spacy
import pandas as pd    
import collections
from collections import Counter
import pickle
from string import punctuation
from wordcloud import WordCloud 
import matplotlib.pyplot as plt

from newsapi import NewsApiClient

!python -m spacy download en_core_web_lg
import spacy.cli
spacy.cli.download("en_core_web_lg")
import en_core_web_lg
nlp_eng = en_core_web_lg.load()

newsapi = NewsApiClient (api_key='API_KEY_HERE')

def getSomething(x):
  temp = newsapi.get_everything(q='coronavirus', language='en', from_param='2020-10-02', to='2020-10-31', sort_by='relevancy', page=x)
  return temp

articles = list(map(getSomething, range(1,6)))


title = []
description = []
content = []
dados = []

for i, article in enumerate(articles):
    for x in article['articles']:
        title = x['title']
        description = x['description']
        content = x['content']
        dados.append({'title':title, 'desc':description, 'content':content})

print(len(dados))

df = pd.DataFrame(dados)
df = df.dropna()
df.head()

def get_keywords_eng(text):
  result = []
  doc = nlp_eng(text)
  pos_tag = ['VERB', 'NOUN', 'PROPN']

  for token in doc:
    if (token.text in nlp_eng.Defaults.stop_words or token.text in punctuation):
      continue
    if (token.pos_ in pos_tag):
      result.append(token.text)

    return result

results = []

for content in df.content.values:
    results.append([('#' + x[0]) for x in Counter(get_keywords_eng(content)).most_common(5)])
df['keywords'] = results

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
